{
    "contents" : "## Lending Club Loan Stats 2015 - Final Project\n\n## SETUP\n## read in the data\nloans <- read.csv(\"loanstats_trimmed.csv\")\n\n## grab some covariates of interest\n# loans <- loanstats[,c(3,6,7,12,13,14,16,21,24,25,26,27,30,33,34,35,36,37,52)]\nhead(loans) ## see newly created data table\n\n## check which covariates R recognizes as factors\nclass(loans$term) ## example - shows R recognizes \"term\" as a factor\n\n\n## DESCRIBE DATA\nhist(loans$int_rate, col=\"lightblue\", xlab=\"Interest Rate\", main=\"\")\nhist(loans$loan_amnt, col=\"lightblue\", xlab=\"Loan Amount\", main=\"\")\n\nplot(loans$int_rate[loans$revol_util>.95])\nplot(loans$int_rate[loans$revol_util<.05])\n\n\n## RUN A REGRESSION\nloanslm <- glm(int_rate~., data=loans)\n1 - loanslm$deviance/loanslm$null.deviance ## Calculates R-squared\n\n\n## OUTLIERS\n## calculate the standardized residuals for loanslm (n-k-1 = 84192) \nloanslm.sigma.hat <- (loanslm$dev/84192)**0.5\n## add a column for predicted values to the loans data frame\nloans$predict <- predict(loanslm)\n## add a column for the residuals\nloans$resid <- loans$int_rate - loans$predict\n## calculate the standardized residuals\nloans$std.resid <- loans$resid / loanslm.sigma.hat\n## add in the outlier p-values\nloans$pvals <- 2*pnorm(-abs(loans$std.resid))\n## show observations with smallest p-values. These loans are outliers,\n## and for some reason have an interest rate that is much different than\n## what our model predicts\nloans.ordered <- loans[order(loans$pvals),]\nhead(loans.ordered)\n\n\n## FALSE DISCOVERY\n## grab p-values\npvals <- summary(loanslm)$coef[-1,4] #-1 to drop the intercept\n## plot them: it looks like we have some signal here\nhist(pvals, xlab=\"p-value\", main=\"\", col=\"lightblue\")\n\n## At 5% FDR, we get 36 `signif'\nsource(\"fdr.R\")\nalpha <- fdr_cut(pvals, .05) ## cutoff\nsignif <- which(pvals <= alpha) ## which are significant\nlength(signif)  ## the number significant\nnames(pvals)[pvals<alpha] ## those variable significant at alpha=0.05\n\n## Re-run a cut regression using only these 36\n## [pulled from semiconductor ex - NEED TO DO DIFFERENTLY because we have factors]\n# get names of variables to include\ncutvar <- c(\"int_rate\", rownames(summary(loanslm)$coef)[-1][signif]) \n# run regression on these alone\nloanslm_cut <- glm(int_rate ~ ., data=loans[,cutvar]) ## DOESN'T WORK\nsummary(loanslm_cut)\n# new in-sample R2: drops to\n1 - loanslm_cut$deviance/loanslm_cut$null.deviance\n\n\n## LASSO REGRESSION\n\nlibrary(gamlr)\nsource(\"naref.R\")\nmmloans <- sparse.model.matrix(int_rate ~ ., data=naref(loans))[,-1]\ny <- loans$int_rate # pull out `y' too just for convenience\n\n## note, I need lambda.min.ratio=1e-4 because otherwise we don't get a path\n## out to complex enough models (i.e. cv err is still decreasing at termination)\ncv.loans <- cv.gamlr(mmloans, y, lmr=1e-4, verb=TRUE )\nn <- nrow(mmloans) # there are 84,277 loans in our dataset\n# plot to visualize\nplot(cv.loans,main=\"OOS R-Squared for CV Lasso\")\n# find the OOS R-Squared\nsummary(cv.loans)[cv.loans$seg.min,] # min avg OOS R2\nsummary(cv.loans)[cv.loans$seg.1se,] # 1se rule\n\n## compare the AICc, AIC, and BIC selection to each other and the CV rules\nsummary(cv.loans$gamlr)[which.min(AIC(cv.loans$gamlr)),] # AIC\nsummary(cv.loans$gamlr)[which.min(AICc(cv.loans$gamlr)),] # AICc\nsummary(cv.loans$gamlr)[which.min(BIC(cv.loans$gamlr)),] # BIC\n\n## plot CV results and the various IC\nll <- log(cv.loans$gamlr$lambda) ## the sequence of lambdas\n\nplot(ll, AIC(cv.loans$gamlr)/n, xlab=\"log lambda\", ylab=\"IC/n\", pch=21, bg=\"orange\")\nabline(v=ll[which.min(AIC(cv.loans$gamlr))], col=\"orange\", lty=3)\nabline(v=ll[which.min(BIC(cv.loans$gamlr))], col=\"green\", lty=3)\nabline(v=ll[which.min(AICc(cv.loans$gamlr))], col=\"black\", lty=3)\npoints(ll, BIC(cv.loans$gamlr)/n, pch=21, bg=\"green\")\npoints(ll, AICc(cv.loans$gamlr)/n, pch=21, bg=\"black\")\nlegend(\"topleft\", bty=\"n\", fill=c(\"black\",\"orange\",\"green\"),legend=c(\"AICc\",\"AIC\",\"BIC\"))\n\n## show CV and IC results together in a path plot\npar(mfrow=c(1,1))\nplot(cv.loans$gamlr, col=\"grey\",main=\"Selected Model Betas vs Log Lambda\")\nabline(v=ll[which.min(AICc(cv.loans$gamlr))], col=\"black\", lty=2)\nabline(v=ll[which.min(AIC(cv.loans$gamlr))], col=\"orange\", lty=2)\nabline(v=ll[which.min(BIC(cv.loans$gamlr))], col=\"green\", lty=2)\nabline(v=log(cv.loans$lambda.min), col=\"blue\", lty=2)\nabline(v=log(cv.loans$lambda.1se), col=\"purple\", lty=2)\nlegend(\"topright\", bty=\"n\", lwd=1,\n  col=c(\"black\",\"orange\",\"green\",\"blue\",\"purple\"),\n  legend=c(\"AICc\",\"AIC\",\"BIC\",\"CV.min\",\"CV.1se\"))\n\n## print the top three int_rate effects\nprint(coef(cv.loans, select=\"1se\"))\n\n\n## CAUSAL TREATMENT EFFECTS\n\n# the naive value of beta on total credit lines\ncoef(cv.loans)[\"total_acc\",] # -0.00040\n\n## a new model matrix excluding total_acc\nx <- mmloans[, -grep(\"total_acc\",colnames(mmloans))]\n## pull total_acc out as a separate vector (treatment)\nd <- mmloans[, \"total_acc\"]\n\n## step 1: fit the treatment regression for Total Credit Lines on x.\n## said another way, predict total_acc from all other covariates\ntreat <- gamlr(x,d)\n## grab predicted dhat from fitted betas\ndhat <- predict(treat, x, type=\"response\")\n## compare d vs. dhat\nplot(dhat,d,bty=\"n\",pch=21,bg=8,main=\"Total Credit Lines Treatment Effect\")\n## calculate in sample R-squared for the d on x regression\ncor(drop(dhat),d)^2\n\n## step 2: using the double-lasso algorithm from class, we just put dhat into\n## the model without any penalty (using the free argument).\n## Re-run lasso to estimate independent effect of Total Credit Lines\ncausal <- gamlr(cBind(d,dhat,x),y,free=2)\n## calculate beta\ncoef(causal)[\"d\",]\n## beta is -0.00049 (close to naive estimate), meaning that\n## total credit lines has a causal effect.\n\n\n## BOOTSTRAP\n\n## bootstrap the lambdas using a for loop.\n## note we don't need cv.gamlr here, just gamlr\nB <- 50 # more samples is better, but we're not picky\nbootgamma <- rep(0,B)\nfor(b in 1:B){\n\t## create a matrix of resampled indices\n\tib <- sample(1:n, n,replace=TRUE)\n\t## create the resampled data\n\txb <- x[ib,]\n\tdb <- d[ib]\n\tyb <- y[ib]\n\t## run the treatment regression\n\ttreatb <- gamlr(xb,db)\n\tdhatb <- predict(treatb,xb)\n\t\n\tfitb <- gamlr(cBind(db,dhatb,xb),yb,free=2)\n\tbootgamma[b] <- coef(fitb)[\"db\",]\n\tprint(b)\n}\n\n## plot histogram\nhist(bootgamma,col=rgb(1,0,0,.5),freq=FALSE,xlim=c(-.0006,-.0004),\n\tylim=c(0,20000),xlab=\"lambda\",main=\"Histogram of Selected Lambdas\")\n\n## Principal Components\nlibrary(maptpx)\nloans_less_int <- loans[,-3]\nloans_less_int\nsummary(factor(loans_less_int$term))\nf.loans_less_int <- factor(loans_less_int$term)\nf.loans_less_int\nhead(factor(f.loans_less_int))\n\nx <- as.simple_triplet_matrix(loans_less_int)\nx2 <- transform(race=factor(race))\n\nloansTopics <- topics(x,K=2:25)\nhelp(topics)\npcloans <- prcomp(x, scale = TRUE)\nplot(pcloans)\nmtext(side=1, \"FX Principle Components\",  line=1, font=2)\nsummary(pcfx)\nfactored_loans_less_int <- factor(loans_less_int)\n\npredict(pcfx)[,1:2]\nzpcfx <- predict(pcfx)\nplot(zpcfx[,1:2], main=\"\")\n#PC1 Furthest points\nround(zpcfx[order(zpcfx[,1])[1:10],1],1)\nround(zpcfx[order(-zpcfx[,1])[1:10],1],1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1433300230657.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4083925005",
    "id" : "BC5DFBB",
    "lastKnownWriteTime" : 1433540007,
    "path" : "C:/Users/Eddie/Google Drive/Academics/Big Data/LendingTree/loanstats.R",
    "project_path" : "loanstats.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}